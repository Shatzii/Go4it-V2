version: '3.8'

services:
  # Ollama - Local LLM serving platform
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./ai-models:/models
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    networks:
      - ai-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Text Generation WebUI for model management
  text-generation-webui:
    image: atinoda/text-generation-webui:default
    ports:
      - "7860:7860"
    volumes:
      - ./ai-models:/app/models
      - ./text-generation-webui:/app/characters
    environment:
      - CLI_ARGS="--listen --auto-devices --model-dir /app/models"
    restart: unless-stopped
    networks:
      - ai-network
    depends_on:
      - ollama

  # Local Vector Database for embeddings
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
    restart: unless-stopped
    networks:
      - ai-network

  # Model Download Service
  model-downloader:
    build:
      context: .
      dockerfile: Dockerfile.model-downloader
    volumes:
      - ./ai-models:/models
    environment:
      - MODELS_TO_DOWNLOAD=mistral:7b-instruct,llama3.2:3b,phi3:mini,qwen2.5:7b
    restart: "no"
    networks:
      - ai-network
    depends_on:
      - ollama

  # Main Application with Local AI
  shatzii-app:
    build:
      context: .
      dockerfile: Dockerfile.local-ai
    ports:
      - "5000:5000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:password@db:5432/shatzii_prod
      - JWT_SECRET=your-super-secure-jwt-secret-here
      - LOCAL_AI_MODE=true
      - OLLAMA_BASE_URL=http://ollama:11434
      - QDRANT_URL=http://qdrant:6333
      - TEXTGEN_API_URL=http://text-generation-webui:7860
    depends_on:
      - db
      - redis
      - ollama
      - qdrant
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./ai-models:/app/ai-models
    restart: unless-stopped
    networks:
      - ai-network

  # PostgreSQL Database
  db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=shatzii_prod
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - ai-network

  # Redis for caching
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - ai-network

  # Nginx with local AI routing
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx-local.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - shatzii-app
      - text-generation-webui
    restart: unless-stopped
    networks:
      - ai-network

volumes:
  postgres_data:
  redis_data:
  ollama_data:
  qdrant_data:

networks:
  ai-network:
    driver: bridge